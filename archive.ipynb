{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88154ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import box\n",
    "import json\n",
    "from datetime import date # –ü–æ—Ç—Ä—ñ–±–Ω–æ –¥–ª—è –æ–±—Ä–æ–±–∫–∏ –æ–±'—î–∫—Ç—ñ–≤ date\n",
    "\n",
    "# --- –ï–ú–£–õ–Ø–¶–Ü–Ø/–ö–û–ù–°–¢–ê–ù–¢–ò ---\n",
    "# –ü—Ä–∏–ø—É—Å–∫–∞—î–º–æ, —â–æ —Ü—ñ –∑–º—ñ–Ω–Ω—ñ/—Ñ—É–Ω–∫—Ü—ñ—ó –≤–∏–∑–Ω–∞—á–µ–Ω—ñ –¥–µ—Å—å –≤–∏—â–µ —É –≤–∞—à–æ–º—É –∫–æ–¥—ñ:\n",
    "# folder_data, deforestation_by_tile, MIN_DAYS_BETWEEN, get_tile_bounds\n",
    "\n",
    "# –§–∞–π–ª, –∫—É–¥–∏ –±—É–¥—É—Ç—å –∑–±–µ—Ä—ñ–≥–∞—Ç–∏—Å—è –≤—Å—ñ —Å—Ç–≤–æ—Ä–µ–Ω—ñ –ø–∞—Ä–∏\n",
    "PAIRS_OUTPUT_FILE = 'seasonal_pairs_metadata.jsonl' \n",
    "# –ì–ª–æ–±–∞–ª—å–Ω–∏–π –ª–æ–∫ –¥–ª—è –±–µ–∑–ø–µ—á–Ω–æ–≥–æ –∑–∞–ø–∏—Å—É –≤ —Å–ø—ñ–ª—å–Ω–∏–π —Ñ–∞–π–ª (–Ω–µ–æ–±—Ö—ñ–¥–Ω–∏–π –¥–ª—è multiprocessing)\n",
    "FILE_LOCK = multiprocessing.Lock()\n",
    "\n",
    "\n",
    "# --- –î–û–ü–û–ú–Ü–ñ–ù–ê –§–£–ù–ö–¶–Ü–Ø –î–õ–Ø –°–ï–†–Ü–ê–õ–Ü–ó–ê–¶–Ü–á ---\n",
    "def json_serial(obj):\n",
    "    \"\"\"JSON serializer for objects not serializable by default json code\"\"\"\n",
    "    if isinstance(obj, date):\n",
    "        return obj.isoformat()\n",
    "    # –°–µ—Ä—ñ–∞–ª—ñ–∑—É—î–º–æ –æ–±'—î–∫—Ç–∏ Shapely Geometry (—è–∫—â–æ –≤–æ–Ω–∏ —î)\n",
    "    if hasattr(obj, '__geo_interface__'):\n",
    "        return obj.__geo_interface__\n",
    "    raise TypeError (\"Type %s not serializable\" % type(obj))\n",
    "\n",
    "# --- –§–£–ù–ö–¶–Ü–Ø –î–õ–Ø –ü–ê–†–ê–õ–ï–õ–¨–ù–û–á –û–ë–†–û–ë–ö–ò (–ó –ë–ï–ó–ü–ï–ß–ù–ò–ú –ó–ê–ü–ò–°–û–ú) ---\n",
    "def create_pairs_for_deforestation(defor_data):\n",
    "    \"\"\"\n",
    "    –°—Ç–≤–æ—Ä—é—î —Å–µ–∑–æ–Ω–Ω—ñ –ø–∞—Ä–∏ –∑–æ–±—Ä–∞–∂–µ–Ω—å –¥–ª—è –æ–¥–Ω—ñ—î—ó –ø–æ–¥—ñ—ó –≤–∏—Ä—É–±–∫–∏ —Ç–∞ –∑–∞–ø–∏—Å—É—î —ó—Ö —É —Ñ–∞–π–ª.\n",
    "\n",
    "    Args:\n",
    "        defor_data (tuple): –ö–æ—Ä—Ç–µ–∂, —â–æ –º—ñ—Å—Ç–∏—Ç—å:\n",
    "                            (defor, tile, summer_images, other_seasons)\n",
    "\n",
    "    Returns:\n",
    "        int: –ö—ñ–ª—å–∫—ñ—Å—Ç—å —É—Å–ø—ñ—à–Ω–æ —Å—Ç–≤–æ—Ä–µ–Ω–∏—Ö —Ç–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–∏—Ö –ø–∞—Ä.\n",
    "    \"\"\"\n",
    "    defor, tile, summer_images, other_seasons = defor_data\n",
    "    local_pairs_count = 0\n",
    "    centroid = defor['geometry'].centroid\n",
    "\n",
    "    # –¢–∏–º—á–∞—Å–æ–≤–∏–π —Å–ø–∏—Å–æ–∫ –¥–ª—è –∑–±–æ—Ä—É –ø–∞—Ä, —è–∫—ñ –∑–≥–µ–Ω–µ—Ä—É–≤–∞–≤ —Ü–µ–π –ø—Ä–æ—Ü–µ—Å\n",
    "    pairs_to_write = []\n",
    "\n",
    "    # –°—Ç–≤–æ—Ä—é—î–º–æ –ø–∞—Ä–∏ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Å–µ–∑–æ–Ω—É\n",
    "    for season_name, season_images in other_seasons.items():\n",
    "        for summer_img in summer_images:\n",
    "            \n",
    "            # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –º–µ–∂ –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –≤–∏–¥–∏–º–æ—Å—Ç—ñ\n",
    "            try:\n",
    "                summer_bounds = box(*get_tile_bounds(summer_img['tci_path']))\n",
    "            except Exception:\n",
    "                continue\n",
    "            \n",
    "            # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –≤–∏–¥–∏–º–æ—Å—Ç—ñ centroid —É –ª—ñ—Ç–Ω—å–æ–º—É –∑–Ω—ñ–º–∫—É\n",
    "            if not Point(centroid).within(summer_bounds):\n",
    "                continue\n",
    "                \n",
    "            for other_img in season_images:\n",
    "                days_diff = abs((other_img['date'] - summer_img['date']).days)\n",
    "                \n",
    "                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –º—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π —á–∞—Å–æ–≤–∏–π —ñ–Ω—Ç–µ—Ä–≤–∞–ª\n",
    "                if days_diff < MIN_DAYS_BETWEEN:\n",
    "                    continue\n",
    "                \n",
    "                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ –≤–∏—Ä—É–±–∫–∞ –≤–∏–¥–∏–º–∞ –≤ \"—ñ–Ω—à–æ–º—É\" –∑–Ω—ñ–º–∫—É\n",
    "                try:\n",
    "                    other_bounds = box(*get_tile_bounds(other_img['tci_path']))\n",
    "                except Exception:\n",
    "                    continue\n",
    "                    \n",
    "                if not Point(centroid).within(other_bounds):\n",
    "                    continue\n",
    "                \n",
    "                # –ó–∞–º—ñ—Å—Ç—å pairs.append(), –¥–æ–¥–∞—î–º–æ –¥–æ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Å–ø–∏—Å–∫—É\n",
    "                pair = {\n",
    "                    'summer_img': summer_img,\n",
    "                    'other_img': other_img,\n",
    "                    'season_pair': f'summer_{season_name}',\n",
    "                    'deforestation': defor,\n",
    "                    'centroid': centroid,\n",
    "                    'tile': tile\n",
    "                }\n",
    "                \n",
    "                pairs_to_write.append(pair)\n",
    "                local_pairs_count += 1\n",
    "                \n",
    "    # --- –ë–ï–ó–ü–ï–ß–ù–ò–ô –ó–ê–ü–ò–° –£ –§–ê–ô–õ ---\n",
    "    if pairs_to_write:\n",
    "        # –ë–ª–æ–∫—É—î–º–æ —Ñ–∞–π–ª, —â–æ–± —ñ–Ω—à–∏–π –ø—Ä–æ—Ü–µ—Å –Ω–µ –∑–∞–ø–∏—Å—É–≤–∞–≤ –æ–¥–Ω–æ—á–∞—Å–Ω–æ\n",
    "        with FILE_LOCK:\n",
    "            with open(PAIRS_OUTPUT_FILE, 'a', encoding='utf-8') as f:\n",
    "                for pair in pairs_to_write:\n",
    "                    # –°–µ—Ä—ñ–∞–ª—ñ–∑—É—î–º–æ –æ–±'—î–∫—Ç –ø–µ—Ä–µ–¥ –∑–∞–ø–∏—Å–æ–º\n",
    "                    json_line = json.dumps(pair, default=json_serial)\n",
    "                    f.write(json_line + '\\n')\n",
    "                    \n",
    "    return local_pairs_count\n",
    "\n",
    "# --- –û–°–ù–û–í–ù–ò–ô –ë–õ–û–ö –ü–ê–†–ê–õ–ï–õ–¨–ù–û–á –û–ë–†–û–ë–ö–ò ---\n",
    "\n",
    "def run_pair_creation():\n",
    "    \"\"\"–ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –¥–ª—è –∑–∞–ø—É—Å–∫—É —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø–∞—Ä.\"\"\"\n",
    "    \n",
    "    print(\"üîÑ –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å–µ–∑–æ–Ω–Ω–∏—Ö –ø–∞—Ä —Ç–∞ –∑–∞–ø–∏—Å –Ω–∞ –¥–∏—Å–∫...\")\n",
    "\n",
    "    # 1. –°–∫–∏–¥–∞–Ω–Ω—è —Ñ–∞–π–ª—É (–∞–±–æ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ —ñ—Å–Ω—É–≤–∞–Ω–Ω—è –¥–ª—è –≤—ñ–¥–Ω–æ–≤–ª–µ–Ω–Ω—è)\n",
    "    if os.path.exists(PAIRS_OUTPUT_FILE):\n",
    "        print(f\"‚ö†Ô∏è –§–∞–π–ª {PAIRS_OUTPUT_FILE} —ñ—Å–Ω—É—î. –ë—É–¥–µ –¥–æ–¥–∞–Ω–æ –Ω–æ–≤—ñ –¥–∞–Ω—ñ.\")\n",
    "    else:\n",
    "        print(f\"üìù –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª—É: {PAIRS_OUTPUT_FILE}\")\n",
    "\n",
    "    # 2. –ó–±—ñ—Ä –≤—Å—ñ—Ö –∑–∞–≤–¥–∞–Ω—å\n",
    "    tasks = []\n",
    "    tiles_to_process = ['T36UYA', 'T36UXA']\n",
    "    \n",
    "    for tile in tiles_to_process:\n",
    "        # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–ª—è –ø–æ—Ç–æ—á–Ω–æ–≥–æ —Ç–∞–π–ª—É (—Ü–µ –Ω–µ –∑–º—ñ–Ω—é—î—Ç—å—Å—è)\n",
    "        tile_images = [img for img in folder_data if img['tile'] == tile]\n",
    "        \n",
    "        # –ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Å–µ–∑–æ–Ω—É (—Ü–µ –Ω–µ –∑–º—ñ–Ω—é—î—Ç—å—Å—è)\n",
    "        summer_images = [img for img in tile_images if img['season'] == 'summer']\n",
    "        other_seasons = {\n",
    "            'autumn': [img for img in tile_images if img['season'] == 'autumn'],\n",
    "            'winter': [img for img in tile_images if img['season'] == 'winter'],\n",
    "            'spring': [img for img in tile_images if img['season'] == 'spring']\n",
    "        }\n",
    "        \n",
    "        # –§–æ—Ä–º—É—î–º–æ —Å–ø–∏—Å–æ–∫ –∑–∞–≤–¥–∞–Ω—å: –æ–¥–Ω–∞ –≤–∏—Ä—É–±–∫–∞ = –æ–¥–Ω–µ –∑–∞–≤–¥–∞–Ω–Ω—è\n",
    "        for defor in deforestation_by_tile[tile]:\n",
    "            tasks.append((defor, tile, summer_images, other_seasons))\n",
    "\n",
    "    num_processes = 7 # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ 4 —è–¥—Ä–∞, —è–∫ –ø—Ä–æ—Å–∏–ª–∏\n",
    "    \n",
    "    print(f\"üõ†Ô∏è –ó–∞–ø—É—Å–∫ –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ—ó –æ–±—Ä–æ–±–∫–∏ –Ω–∞ {num_processes} –ø—Ä–æ—Ü–µ—Å–∞—Ö –¥–ª—è {len(tasks)} –ø–æ–¥—ñ–π –≤–∏—Ä—É–±–∫–∏...\")\n",
    "\n",
    "    # 3. –ó–∞–ø—É—Å–∫ Pool –¥–ª—è –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ–≥–æ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è\n",
    "    with multiprocessing.Pool(processes=num_processes) as pool:\n",
    "        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ imap_unordered –¥–ª—è –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ–≥–æ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è —Ç–∞ tqdm –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—É\n",
    "        results = list(tqdm(pool.imap_unordered(create_pairs_for_deforestation, tasks), \n",
    "                             total=len(tasks), \n",
    "                             desc=\"–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –ø–∞—Ä —Ç–∞ –∑–∞–ø–∏—Å –Ω–∞ –¥–∏—Å–∫\"))\n",
    "        \n",
    "        total_pairs_created = sum(results)\n",
    "\n",
    "    print(f\"‚úÖ –°—Ç–≤–æ—Ä–µ–Ω–æ —Ç–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–æ {total_pairs_created} —Å–µ–∑–æ–Ω–Ω–∏—Ö –ø–∞—Ä —É —Ñ–∞–π–ª—ñ {PAIRS_OUTPUT_FILE}\")\n",
    "\n",
    "    \n",
    "run_pair_creation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cadbb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å–µ–∑–æ–Ω–Ω–∏—Ö –ø–∞—Ä\n",
    "print(\"üîÑ –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å–µ–∑–æ–Ω–Ω–∏—Ö –ø–∞—Ä...\")\n",
    "pairs = []\n",
    "\n",
    "for tile in ['T36UYA', 'T36UXA']:\n",
    "    # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–ª—è –ø–æ—Ç–æ—á–Ω–æ–≥–æ —Ç–∞–π–ª—É\n",
    "    tile_images = [img for img in folder_data if img['tile'] == tile]\n",
    "    \n",
    "    # –ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Å–µ–∑–æ–Ω—É\n",
    "    summer_images = [img for img in tile_images if img['season'] == 'summer']\n",
    "    other_seasons = {\n",
    "        'autumn': [img for img in tile_images if img['season'] == 'autumn'],\n",
    "        'winter': [img for img in tile_images if img['season'] == 'winter'],\n",
    "        'spring': [img for img in tile_images if img['season'] == 'spring']\n",
    "    }\n",
    "    \n",
    "    # –û–±—Ä–æ–±–∫–∞ –∫–æ–∂–Ω–æ—ó –≤–∏—Ä—É–±–∫–∏\n",
    "    for defor in tqdm(deforestation_by_tile[tile], desc=f\"–û–±—Ä–æ–±–∫–∞ {tile}\"):\n",
    "        centroid = defor['geometry'].centroid\n",
    "        \n",
    "        # –°—Ç–≤–æ—Ä—é—î–º–æ –ø–∞—Ä–∏ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Å–µ–∑–æ–Ω—É\n",
    "        for season_name, season_images in other_seasons.items():\n",
    "            for summer_img in summer_images:\n",
    "                for other_img in season_images:\n",
    "                    days_diff = abs((other_img['date'] - summer_img['date']).days)\n",
    "                    \n",
    "                    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –º—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π —á–∞—Å–æ–≤–∏–π —ñ–Ω—Ç–µ—Ä–≤–∞–ª\n",
    "                    if days_diff < MIN_DAYS_BETWEEN:\n",
    "                        continue\n",
    "                    \n",
    "                    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ –≤–∏—Ä—É–±–∫–∞ –≤–∏–¥–∏–º–∞ –≤ –æ–±–æ—Ö –∑–Ω—ñ–º–∫–∞—Ö\n",
    "                    if not (Point(centroid).within(box(*get_tile_bounds(summer_img['tci_path']))) and\n",
    "                            Point(centroid).within(box(*get_tile_bounds(other_img['tci_path'])))):\n",
    "                        continue\n",
    "                    \n",
    "                    pairs.append({\n",
    "                        'summer_img': summer_img,\n",
    "                        'other_img': other_img,\n",
    "                        'season_pair': f'summer_{season_name}',\n",
    "                        'deforestation': defor,\n",
    "                        'centroid': centroid,\n",
    "                        'tile': tile\n",
    "                    })\n",
    "\n",
    "print(f\"‚úÖ –°—Ç–≤–æ—Ä–µ–Ω–æ {len(pairs)} —Å–µ–∑–æ–Ω–Ω–∏—Ö –ø–∞—Ä\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0868fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –î–æ–¥–∞–π—Ç–µ —Ü–µ–π –∫–æ–¥ –ø–µ—Ä–µ–¥ —Ñ—É–Ω–∫—Ü—ñ—î—é run_patch_generation()\n",
    "\n",
    "from shapely.geometry import shape\n",
    "from datetime import datetime, date # –î–æ–¥–∞—Ç–∫–æ–≤—ñ —ñ–º–ø–æ—Ä—Ç–∏ –¥–ª—è –∫–æ—Ä–µ–∫—Ç–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥—É\n",
    "\n",
    "PAIRS_METADATA_FILE = 'seasonal_pairs_metadata.jsonl'\n",
    "# –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ 512, —è–∫ —É –≤–∞—à–æ–º—É –ø–ª–∞–Ω—ñ\n",
    "PATCH_SIZE_FINAL = 500\n",
    "\n",
    "def load_and_prepare_pairs():\n",
    "    \"\"\"–ß–∏—Ç–∞—î –≤—Å—ñ –ø–∞—Ä–∏ –∑ .jsonl, –ø–µ—Ä–µ—Ç–≤–æ—Ä—é—î –≥–µ–æ–º–µ—Ç—Ä—ñ—é —Ç–∞ –∑–±–∏—Ä–∞—î —É–Ω—ñ–∫–∞–ª—å–Ω—ñ ID.\"\"\"\n",
    "    all_pairs = []\n",
    "    unique_defor_ids = set()\n",
    "    \n",
    "    try:\n",
    "        with open(PAIRS_METADATA_FILE, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    pair = json.loads(line)\n",
    "                    \n",
    "                    # 1. –ü–∞—Ä—Å–∏–Ω–≥ –¥–∞—Ç (–Ω–µ–æ–±—Ö—ñ–¥–Ω–æ –¥–ª—è —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É days_difference)\n",
    "                    pair['summer_img']['date'] = datetime.strptime(pair['summer_img']['date'].split('T')[0], '%Y-%m-%d').date()\n",
    "                    pair['other_img']['date'] = datetime.strptime(pair['other_img']['date'].split('T')[0], '%Y-%m-%d').date()\n",
    "                    \n",
    "                    # 2. –ü–∞—Ä—Å–∏–Ω–≥ —Ü–µ–Ω—Ç—Ä–æ—ó–¥–∞ (shapely Point)\n",
    "                    # pair['centroid'] —î –æ–±'—î–∫—Ç–æ–º GeoJSON {\"type\": \"Point\", \"coordinates\": [...]}.\n",
    "                    pair['centroid'] = shape(pair['centroid'])\n",
    "                    \n",
    "                    # 3. –ó–±—ñ—Ä ID\n",
    "                    unique_defor_ids.add(pair['deforestation']['id'])\n",
    "                    \n",
    "                    all_pairs.append(pair)\n",
    "                except Exception as e:\n",
    "                    print(f\"–ü–æ–º–∏–ª–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥—É —Ä—è–¥–∫–∞ –≤ {PAIRS_METADATA_FILE}: {e}\")\n",
    "                    continue\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå –§–∞–π–ª {PAIRS_METADATA_FILE} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.\")\n",
    "        return [], set()\n",
    "\n",
    "    return all_pairs, unique_defor_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c318d093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- –î–û–ü–û–ú–Ü–ñ–ù–Ü –§–£–ù–ö–¶–Ü–á –î–õ–Ø PARALLEL. (–ø–æ—Ç—Ä—ñ–±–Ω–æ –¥–æ–¥–∞—Ç–∏ —É –í–∞—à –∫–æ–¥) ---\n",
    "\n",
    "# –ü–†–ò–ú–Ü–¢–ö–ê: –î–ª—è —Ä–æ–±–æ—Ç–∏ —Ü—å–æ–≥–æ –±–ª–æ–∫—É –ø–æ—Ç—Ä—ñ–±–Ω–æ, —â–æ–± —Ñ—É–Ω–∫—Ü—ñ—ó \n",
    "# `crop_patch_around_centroid`, `find_band_path`, `get_tile_bounds`\n",
    "# –±—É–ª–∏ –≤–∏–∑–Ω–∞—á–µ–Ω—ñ –≤–∏—â–µ —É –í–∞—à–æ–º—É –Ω–æ—É—Ç–±—É—Ü—ñ.\n",
    "\n",
    "# –°—Ç–≤–æ—Ä—é—î–º–æ —Ñ—ñ–∫—Ç–∏–≤–Ω—É —Ñ—É–Ω–∫—Ü—ñ—é –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—ó, —è–∫–∞ –µ–º—É–ª—é—î –≤–∞—à—É crop_patch_around_centroid, \n",
    "# –∞–ª–µ –±–µ—Ä–µ –Ω–∞ –≤—Ö—ñ–¥ folder_path —ñ band_name, –∞ –Ω–µ tci_path (—è–∫ —É 6-–∫–∞–Ω–∞–ª—å–Ω—ñ–π –≤–µ—Ä—Å—ñ—ó)\n",
    "# –û—Å–∫—ñ–ª—å–∫–∏ –≤–∏ –Ω–∞–¥–∞–ª–∏ –∫–æ–¥, —â–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î tci_path, –º–∏ –∑–∞–ª–∏—à–∞—î–º–æ –π–æ–≥–æ, \n",
    "# –∞–ª–µ –∑–∞—É–≤–∞–∂—Ç–µ, —â–æ 6-–∫–∞–Ω–∞–ª—å–Ω–∞ –≤–µ—Ä—Å—ñ—è –±—É–ª–∞ –± –∫—Ä–∞—â–æ—é.\n",
    "\n",
    "H_GT = np.eye(3) # –ì–æ–º–æ–≥—Ä–∞—Ñ—ñ—è Ground Truth\n",
    "NUM_WORKERS = os.cpu_count() - 1 if os.cpu_count() > 1 else 1\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "def process_single_pair_final(i, pair_data, output_dir, patch_size, val_ids, h_gt):\n",
    "    \"\"\"\n",
    "    –û–±—Ä–æ–±–ª—è—î —Ç–∞ –∑–±–µ—Ä—ñ–≥–∞—î –ø–∞—Ç—á—ñ –¥–ª—è –æ–¥–Ω—ñ—î—ó –ø–∞—Ä–∏ –∑–Ω—ñ–º–∫—ñ–≤.\n",
    "    –¶—è —Ñ—É–Ω–∫—Ü—ñ—è –≤–∏–∫–æ–Ω—É—î—Ç—å—Å—è –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ.\n",
    "    \"\"\"\n",
    "    \n",
    "    # –í–∏—Ä—ñ–∑–∞—î–º–æ –ø–∞—Ç—á—ñ –¥–ª—è –æ–±–æ—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å\n",
    "    patch_summer, meta_summer = crop_patch_around_centroid(\n",
    "        pair_data['summer_img']['tci_path'], \n",
    "        pair_data['centroid'], \n",
    "        patch_size\n",
    "    )\n",
    "    \n",
    "    patch_other, meta_other = crop_patch_around_centroid(\n",
    "        pair_data['other_img']['tci_path'], \n",
    "        pair_data['centroid'], \n",
    "        patch_size\n",
    "    )\n",
    "    \n",
    "    # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –ø–æ–º–∏–ª–∫–æ–≤—ñ –ø–∞—Ç—á—ñ\n",
    "    if patch_summer is None or patch_other is None:\n",
    "        return None\n",
    "    \n",
    "    # –í–∏–∑–Ω–∞—á–∞—î–º–æ, –∫—É–¥–∏ –∑–±–µ—Ä—ñ–≥–∞—Ç–∏ (train/val)\n",
    "    split = 'val' if pair_data['deforestation']['id'] in val_ids else 'train'\n",
    "    pair_dir = os.path.join(output_dir, split, f\"pair_{i:04d}\")\n",
    "    os.makedirs(pair_dir, exist_ok=True)\n",
    "    \n",
    "    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –ø–∞—Ç—á—ñ —Ç–∞ –ì–æ–º–æ–≥—Ä–∞—Ñ—ñ—é\n",
    "    np.save(os.path.join(pair_dir, 'img1.npy'), patch_summer) # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ img1/img2 –¥–ª—è LoFTR\n",
    "    np.save(os.path.join(pair_dir, 'img2.npy'), patch_other)\n",
    "    np.save(os.path.join(pair_dir, 'homography.npy'), h_gt) \n",
    "    \n",
    "    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –º–µ—Ç–∞–¥–∞–Ω—ñ\n",
    "    metadata = {\n",
    "        'img1_path': pair_data['summer_img']['tci_path'],\n",
    "        'img2_path': pair_data['other_img']['tci_path'],\n",
    "        'date_img1': pair_data['summer_img']['date'].isoformat(),\n",
    "        'date_img2': pair_data['other_img']['date'].isoformat(),\n",
    "        'season_pair': pair_data['season_pair'],\n",
    "        'deforestation_id': pair_data['deforestation']['id'],\n",
    "        'centroid': pair_data['centroid'].__geo_interface__,\n",
    "        'tile': pair_data['tile'],\n",
    "        'days_difference': abs((pair_data['other_img']['date'] - pair_data['summer_img']['date']).days)\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(pair_dir, 'metadata.json'), 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "        \n",
    "    # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ —ñ–Ω–¥–µ–∫—Å –ø–∞—Ä–∏ –¥–ª—è –ø–æ–¥–∞–ª—å—à–æ—ó —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏\n",
    "    return i\n",
    "\n",
    "\n",
    "def run_patch_generation():\n",
    "    \"\"\"–ó–∞–ø—É—Å–∫–∞—î –ø—Ä–æ—Ü–µ—Å –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –ø–∞—Ç—á—ñ–≤ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –¥–∞–Ω–∏—Ö –∑ JSONL.\"\"\"\n",
    "    \n",
    "    # 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–∞ –ø—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö\n",
    "    print(f\"üìñ –ß–∏—Ç–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö –∑ {PAIRS_METADATA_FILE}...\")\n",
    "    all_pairs, unique_defor_ids = load_and_prepare_pairs()\n",
    "    \n",
    "    if not all_pairs:\n",
    "        print(\"‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∫–æ—Ä–µ–∫—Ç–Ω–∏—Ö –ø–∞—Ä –¥–ª—è –æ–±—Ä–æ–±–∫–∏.\")\n",
    "        return\n",
    "\n",
    "    # 2. –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –Ω–∞ train/val\n",
    "    print(\"‚úÇÔ∏è –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –Ω–∞ Train/Val –∑–∞ ID –≤–∏—Ä—É–±–æ–∫...\")\n",
    "    unique_defor_ids_list = list(unique_defor_ids)\n",
    "    np.random.seed(42)\n",
    "    val_defor_ids = set(np.random.choice(\n",
    "        unique_defor_ids_list, \n",
    "        size=int(0.2 * len(unique_defor_ids_list)), \n",
    "        replace=False\n",
    "    ))\n",
    "    \n",
    "    # 3. –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ–π\n",
    "    print(f\"üíæ –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –ø–∞—Ç—á—ñ–≤ —Ç–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –¥–∞—Ç–∞—Å–µ—Ç—É –≤ {OUTPUT_DIR}...\")\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, 'train'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, 'val'), exist_ok=True)\n",
    "\n",
    "    # 4. –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞–≤–¥–∞–Ω—å –¥–ª—è –ø–∞—Ä–∞–ª–µ–ª—ñ–∑–∞—Ü—ñ—ó\n",
    "    tasks = []\n",
    "    for i, pair in enumerate(all_pairs):\n",
    "        # –ü–µ—Ä–µ–¥–∞—î–º–æ –ª–∏—à–µ –Ω–µ–æ–±—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ —É –ø—É–ª\n",
    "        tasks.append((i, pair, OUTPUT_DIR, PATCH_SIZE_FINAL, val_defor_ids, H_GT))\n",
    "    \n",
    "    print(f\"‚ö°Ô∏è –ó–∞–ø—É—Å–∫ –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ—ó –æ–±—Ä–æ–±–∫–∏ {len(tasks)} –ø–∞—Ä –Ω–∞ {NUM_WORKERS} –ø—Ä–æ—Ü–µ—Å–æ—Ä–∞—Ö...\")\n",
    "\n",
    "    # 5. –ó–∞–ø—É—Å–∫ –ø—É–ª—É –ø—Ä–æ—Ü–µ—Å—ñ–≤\n",
    "    with Pool(NUM_WORKERS) as pool:\n",
    "        # map –ø–æ–≤–µ—Ä—Ç–∞—î —ñ–Ω–¥–µ–∫—Å–∏ —É—Å–ø—ñ—à–Ω–æ –æ–±—Ä–æ–±–ª–µ–Ω–∏—Ö –ø–∞—Ä\n",
    "        results = list(tqdm(pool.starmap(process_single_pair_final, tasks), \n",
    "                            total=len(tasks), \n",
    "                            desc=\"–ü–∞—Ä–∞–ª–µ–ª—å–Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è\"))\n",
    "\n",
    "    successful_indices = [idx for idx in results if idx is not None]\n",
    "    \n",
    "    # 6. –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏\n",
    "    successful_pairs_count = len(successful_indices)\n",
    "    \n",
    "    stats = {\n",
    "        'total_pairs_attempted': len(all_pairs),\n",
    "        'total_pairs_successful': successful_pairs_count,\n",
    "        'train_pairs': len([i for i in successful_indices if all_pairs[i]['deforestation']['id'] not in val_defor_ids]),\n",
    "        'val_pairs': len([i for i in successful_indices if all_pairs[i]['deforestation']['id'] in val_defor_ids]),\n",
    "        'season_distribution': {},\n",
    "        'tile_distribution': {'T36UYA': 0, 'T36UXA': 0}\n",
    "    }\n",
    "\n",
    "    # –û–±—á–∏—Å–ª–µ–Ω–Ω—è —Ä–æ–∑–ø–æ–¥—ñ–ª—É\n",
    "    for i in successful_indices:\n",
    "        pair = all_pairs[i]\n",
    "        season = pair['season_pair']\n",
    "        tile = pair['tile']\n",
    "        \n",
    "        stats['season_distribution'][season] = stats['season_distribution'].get(season, 0) + 1\n",
    "        stats['tile_distribution'][tile] += 1\n",
    "        \n",
    "    with open(os.path.join(OUTPUT_DIR, 'dataset_stats.json'), 'w') as f:\n",
    "        json.dump(stats, f, indent=2)\n",
    "    \n",
    "    # 7. –í–∏–≤—ñ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ (—è–∫ —É –≤–∞—à–æ–º—É –∫–æ–¥—ñ)\n",
    "    print(\"\\n‚úÖ –î–ê–¢–ê–°–ï–¢ –°–¢–í–û–†–ï–ù–û –£–°–ü–Ü–®–ù–û!\")\n",
    "    print(f\"üìä –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —É—Å–ø—ñ—à–Ω–∏—Ö –ø–∞—Ä: {stats['total_pairs_successful']}\")\n",
    "    # ... (—ñ–Ω—à–∏–π –≤–∏–≤—ñ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e0a946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –ø–∞—Ç—á—ñ–≤ —Ç–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –¥–∞—Ç–∞—Å–µ—Ç—É\n",
    "print(\"üíæ –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –ø–∞—Ç—á—ñ–≤ —Ç–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –¥–∞—Ç–∞—Å–µ—Ç—É...\")\n",
    "\n",
    "# –°—Ç–≤–æ—Ä—é—î–º–æ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ–π\n",
    "os.makedirs(os.path.join(OUTPUT_DIR, 'train'), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUTPUT_DIR, 'val'), exist_ok=True)\n",
    "\n",
    "# –†–æ–∑–¥—ñ–ª—è—î–º–æ –ø–∞—Ä–∏ –Ω–∞ train/val (80/20) –∑–∞ –≤–∏—Ä—É–±–∫–∞–º–∏\n",
    "unique_defor_ids = list(set([pair['deforestation']['id'] for pair in all_pairs]))\n",
    "np.random.seed(42)\n",
    "val_ids = set(np.random.choice(unique_defor_ids, size=int(0.2 * len(unique_defor_ids)), replace=False))\n",
    "\n",
    "# –ì–æ–ª–æ–≤–Ω–∏–π —Ü–∏–∫–ª –æ–±—Ä–æ–±–∫–∏ –ø–∞—Ä\n",
    "for i, pair in enumerate(tqdm(all_pairs, desc=\"–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –ø–∞—Ç—á—ñ–≤\")):\n",
    "    # –í–∏—Ä—ñ–∑–∞—î–º–æ –ø–∞—Ç—á—ñ –¥–ª—è –æ–±–æ—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å\n",
    "    patch_summer, meta_summer = crop_patch_around_centroid(\n",
    "        pair['summer_img']['tci_path'], \n",
    "        pair['centroid'], \n",
    "        PATCH_SIZE\n",
    "    )\n",
    "    \n",
    "    patch_other, meta_other = crop_patch_around_centroid(\n",
    "        pair['other_img']['tci_path'], \n",
    "        pair['centroid'], \n",
    "        PATCH_SIZE\n",
    "    )\n",
    "    \n",
    "    # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –ø–æ–º–∏–ª–∫–æ–≤—ñ –ø–∞—Ç—á—ñ\n",
    "    if patch_summer is None or patch_other is None:\n",
    "        continue\n",
    "    \n",
    "    # –í–∏–∑–Ω–∞—á–∞—î–º–æ, –∫—É–¥–∏ –∑–±–µ—Ä—ñ–≥–∞—Ç–∏ (train/val)\n",
    "    split = 'val' if pair['deforestation']['id'] in val_ids else 'train'\n",
    "    pair_dir = os.path.join(OUTPUT_DIR, split, f\"pair_{i:04d}\")\n",
    "    os.makedirs(pair_dir, exist_ok=True)\n",
    "    \n",
    "    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –ø–∞—Ç—á—ñ\n",
    "    np.save(os.path.join(pair_dir, 'img_summer.npy'), patch_summer)\n",
    "    np.save(os.path.join(pair_dir, 'img_other.npy'), patch_other)\n",
    "    \n",
    "    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –º–µ—Ç–∞–¥–∞–Ω—ñ\n",
    "    metadata = {\n",
    "        'summer_img_path': pair['summer_img']['tci_path'],\n",
    "        'other_img_path': pair['other_img']['tci_path'],\n",
    "        'date_summer': pair['summer_img']['date'].strftime('%Y-%m-%d'),\n",
    "        'date_other': pair['other_img']['date'].strftime('%Y-%m-%d'),\n",
    "        'season_summer': 'summer',\n",
    "        'season_other': pair['season_pair'].split('_')[1],\n",
    "        'season_pair': pair['season_pair'],\n",
    "        'deforestation_id': pair['deforestation']['id'],\n",
    "        'centroid': (pair['centroid'].x, pair['centroid'].y),\n",
    "        'tile': pair['tile'],\n",
    "        'grid_position': meta_summer['grid_position'],\n",
    "        'days_difference': abs((pair['other_img']['date'] - pair['summer_img']['date']).days)\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(pair_dir, 'metadata.json'), 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe01df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –ø—Ä–∏–∫–ª–∞–¥—É\n",
    "print(\"üñºÔ∏è –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø—Ä–∏–∫–ª–∞–¥—É –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó...\")\n",
    "sample_pair = all_pairs[0]\n",
    "patch_summer, _ = crop_patch_around_centroid(\n",
    "    sample_pair['summer_img']['tci_path'], \n",
    "    sample_pair['centroid'], \n",
    "    PATCH_SIZE\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(patch_summer)\n",
    "plt.title(f\"–õ—ñ—Ç–æ ({sample_pair['summer_img']['date'].strftime('%Y-%m-%d')})\")\n",
    "plt.axis('off')\n",
    "\n",
    "patch_other, _ = crop_patch_around_centroid(\n",
    "    sample_pair['other_img']['tci_path'], \n",
    "    sample_pair['centroid'], \n",
    "    PATCH_SIZE\n",
    ")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(patch_other)\n",
    "plt.title(f\"{sample_pair['season_pair'].split('_')[1].capitalize()} ({sample_pair['other_img']['date'].strftime('%Y-%m-%d')})\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'sample_pair.jpg'), dpi=150, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c172a292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏\n",
    "print(\"üìä –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç—É...\")\n",
    "stats = {\n",
    "    'total_pairs': len(all_pairs),\n",
    "    'train_pairs': len([p for p in all_pairs if p['deforestation']['id'] not in val_ids]),\n",
    "    'val_pairs': len([p for p in all_pairs if p['deforestation']['id'] in val_ids]),\n",
    "    'season_distribution': {},\n",
    "    'tile_distribution': {'T36UYA': 0, 'T36UXA': 0}\n",
    "}\n",
    "\n",
    "# –†–æ–∑–ø–æ–¥—ñ–ª –∑–∞ —Å–µ–∑–æ–Ω–Ω–∏–º–∏ –ø–∞—Ä–∞–º–∏\n",
    "for season in ['summer_autumn', 'summer_winter', 'summer_spring']:\n",
    "    stats['season_distribution'][season] = len([p for p in all_pairs if p['season_pair'] == season])\n",
    "\n",
    "# –†–æ–∑–ø–æ–¥—ñ–ª –∑–∞ —Ç–∞–π–ª–∞–º–∏\n",
    "for pair in all_pairs:\n",
    "    stats['tile_distribution'][pair['tile']] += 1\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR, 'dataset_stats.json'), 'w') as f:\n",
    "    json.dump(stats, f, indent=2)\n",
    "\n",
    "# –í–∏–≤—ñ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏\n",
    "print(\"\\n‚úÖ –î–ê–¢–ê–°–ï–¢ –°–¢–í–û–†–ï–ù–û –£–°–ü–Ü–®–ù–û!\")\n",
    "print(f\"üìÅ –®–ª—è—Ö: {OUTPUT_DIR}\")\n",
    "print(f\"üìä –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –ø–∞—Ä: {stats['total_pairs']}\")\n",
    "print(f\"   ‚Ä¢ Train: {stats['train_pairs']}\")\n",
    "print(f\"   ‚Ä¢ Val: {stats['val_pairs']}\")\n",
    "print(\"\\n–°–µ–∑–æ–Ω–Ω–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª:\")\n",
    "for season, count in stats['season_distribution'].items():\n",
    "    print(f\"   ‚Ä¢ {season.replace('_', '/').capitalize()}: {count}\")\n",
    "print(\"\\n–†–æ–∑–ø–æ–¥—ñ–ª –∑–∞ —Ç–∞–π–ª–∞–º–∏:\")\n",
    "for tile, count in stats['tile_distribution'].items():\n",
    "    print(f\"   ‚Ä¢ {tile}: {count}\")\n",
    "print(f\"\\nüñºÔ∏è –ü—Ä–∏–∫–ª–∞–¥ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {os.path.join(OUTPUT_DIR, 'sample_pair.jpg')}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
